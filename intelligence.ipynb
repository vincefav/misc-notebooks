{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, StratifiedKFold\n",
    "\n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_excel('favorites.xlsx')\n",
    "\n",
    "def absolute_correlations(col, df=data):\n",
    "    #absolute_values = np.abs(df[col])\n",
    "    corrs = pd.DataFrame(df.select_dtypes(include=[np.number]).corrwith(df[col]), columns=['correlation'])\n",
    "    corrs['absol'] = np.abs(corrs['correlation'])\n",
    "    return corrs.sort_values('absol', ascending=False).drop('absol', axis=1).tail(len(corrs)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Estimating intelligence based on these questions\n",
    "intelligence_scale = (\n",
    "    (8-data['I have difficulty understanding abstract ideas.']) +\n",
    "    (8-data[\"I'm not interested in abstract ideas.\"]) +\n",
    "    data[\"I'm a fast learner.\"]\n",
    ")\n",
    "\n",
    "# Splitting people into above average and below average\n",
    "y = np.where(\n",
    "    intelligence_scale > intelligence_scale.mean(), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Things smart people like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = data['25 things you like'].fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('tfidfvectorizer', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.10500000000000002, max_features=None,\n",
       "        min_df=3, ngram_range=(1, 1), norm='l2', preprocesso...=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=0, silent=True,\n",
       "       subsample=1))])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'tfidfvectorizer__min_df': [3],#np.arange(1,11,1),\n",
    "    'tfidfvectorizer__max_df': np.arange(.08, .12, .005),\n",
    "    'xgbclassifier__n_estimators': [100],\n",
    "    'xgbclassifier__max_depth': np.arange(2,7,1)\n",
    "}\n",
    "\n",
    "kf = StratifiedKFold(n_splits=3)\n",
    "\n",
    "pl = make_pipeline(\n",
    "    TfidfVectorizer(),\n",
    "    XGBClassifier()\n",
    ")\n",
    "\n",
    "grid = GridSearchCV(pl, param_grid, cv=kf, scoring='roc_auc')\\\n",
    ".fit(x, y)\n",
    "\n",
    "clf = grid.best_estimator_\n",
    "\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7959799861973775, 0.016360165681333392)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The model does a good job of predicting intelligence from interests\n",
    "\n",
    "cv = cross_val_score(clf, x, y, cv=kf, scoring='roc_auc')\n",
    "\n",
    "cv.mean(), cv.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words = {}\n",
    "\n",
    "for word, num in clf.named_steps['tfidfvectorizer'].vocabulary_.items():\n",
    "    prob = clf.predict_proba([word])[0][1]\n",
    "    words[word] = prob\n",
    "\n",
    "df_topwords = pd.DataFrame([words]).transpose()\n",
    "df_topwords.columns = ['probability']\n",
    "\n",
    "df_topwords.sort_values('probability', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Default prediction for this model is: 0.014619269408285618\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>harry</th>\n",
       "      <td>0.047004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comedy</th>\n",
       "      <td>0.039199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>others</th>\n",
       "      <td>0.035943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>show</th>\n",
       "      <td>0.031275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shows</th>\n",
       "      <td>0.029064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>helping</th>\n",
       "      <td>0.021652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>green</th>\n",
       "      <td>0.018953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>up</th>\n",
       "      <td>0.017309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conversations</th>\n",
       "      <td>0.017136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dad</th>\n",
       "      <td>0.017021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>science</th>\n",
       "      <td>0.016925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trips</th>\n",
       "      <td>0.015868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>0.011405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>color</th>\n",
       "      <td>0.011116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disney</th>\n",
       "      <td>0.009190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               probability\n",
       "harry             0.047004\n",
       "comedy            0.039199\n",
       "others            0.035943\n",
       "show              0.031275\n",
       "shows             0.029064\n",
       "helping           0.021652\n",
       "green             0.018953\n",
       "up                0.017309\n",
       "conversations     0.017136\n",
       "dad               0.017021\n",
       "science           0.016925\n",
       "trips             0.015868\n",
       "for               0.011405\n",
       "color             0.011116\n",
       "disney            0.009190"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mode = mode(df_topwords['probability'])[0][0]\n",
    "\n",
    "print()\n",
    "print('Default prediction for this model is:', df_mode)\n",
    "print()\n",
    "\n",
    "df_topwords[df_topwords.probability != df_mode]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I am ______\n",
    "\n",
    "Students were asked to fill in the blank 10 times, saying whatever came to mind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = data['I am _______.'].fillna(' ').astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('tfidfvectorizer', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.08, max_features=None, min_df=3,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_...=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=0, silent=True,\n",
       "       subsample=1))])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'tfidfvectorizer__min_df': [3],#np.arange(1,11,1),\n",
    "    'tfidfvectorizer__max_df': np.arange(.08, .12, .005),\n",
    "    'xgbclassifier__n_estimators': [100],\n",
    "    'xgbclassifier__max_depth': np.arange(2,7,1)\n",
    "}\n",
    "\n",
    "kf = StratifiedKFold(n_splits=3)\n",
    "\n",
    "pl = make_pipeline(\n",
    "    TfidfVectorizer(),\n",
    "    XGBClassifier()\n",
    ")\n",
    "\n",
    "grid = GridSearchCV(pl, param_grid, cv=kf, scoring='roc_auc')\\\n",
    ".fit(x, y)\n",
    "\n",
    "clf = grid.best_estimator_\n",
    "\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7602010006901313, 0.00788388208725665)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This model works well too\n",
    "\n",
    "cv = cross_val_score(clf, x, y, cv=kf, scoring='roc_auc')\n",
    "\n",
    "cv.mean(), cv.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = {}\n",
    "\n",
    "for word, num in clf.named_steps['tfidfvectorizer'].vocabulary_.items():\n",
    "    prob = clf.predict_proba([word])[0][1]\n",
    "    words[word] = prob\n",
    "\n",
    "df_topwords = pd.DataFrame([words]).transpose()\n",
    "df_topwords.columns = ['probability']\n",
    "\n",
    "df_topwords.sort_values('probability', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Default prediction for this model is: 0.007261719089001417\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>patient</th>\n",
       "      <td>0.081004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>over</th>\n",
       "      <td>0.076149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>woman</th>\n",
       "      <td>0.073762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hungry</th>\n",
       "      <td>0.033324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>determined</th>\n",
       "      <td>0.022406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>focused</th>\n",
       "      <td>0.011084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>helpful</th>\n",
       "      <td>0.010576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.010411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>going</th>\n",
       "      <td>0.009664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>being</th>\n",
       "      <td>0.009604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loyal</th>\n",
       "      <td>0.009229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>0.009100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>teacher</th>\n",
       "      <td>0.008301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>understanding</th>\n",
       "      <td>0.008247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>empathetic</th>\n",
       "      <td>0.008015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tall</th>\n",
       "      <td>0.006973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>american</th>\n",
       "      <td>0.005945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>responsible</th>\n",
       "      <td>0.005793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               probability\n",
       "patient           0.081004\n",
       "over              0.076149\n",
       "woman             0.073762\n",
       "hungry            0.033324\n",
       "determined        0.022406\n",
       "focused           0.011084\n",
       "helpful           0.010576\n",
       "11                0.010411\n",
       "going             0.009664\n",
       "being             0.009604\n",
       "loyal             0.009229\n",
       "female            0.009100\n",
       "teacher           0.008301\n",
       "understanding     0.008247\n",
       "empathetic        0.008015\n",
       "tall              0.006973\n",
       "american          0.005945\n",
       "responsible       0.005793"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mode = mode(df_topwords['probability'])[0][0]\n",
    "\n",
    "print()\n",
    "print('Default prediction for this model is:', df_mode)\n",
    "print()\n",
    "\n",
    "df_topwords[df_topwords.probability != df_mode]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How would you introduce yourself to a classmate?\n",
    "\n",
    "I told them to write this in a way that emphasized their personality. Swearing and slang were acceptable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = data['Your \"introduction\"'].fillna(' ').astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('tfidfvectorizer', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.085, max_features=None, min_df=3,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth...=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=0, silent=True,\n",
       "       subsample=1))])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'tfidfvectorizer__min_df': [3],#np.arange(1,11,1),\n",
    "    'tfidfvectorizer__max_df': np.arange(.08, .12, .005),\n",
    "    'xgbclassifier__n_estimators': [100],\n",
    "    'xgbclassifier__max_depth': np.arange(2,7,1)\n",
    "}\n",
    "\n",
    "kf = StratifiedKFold(n_splits=3)\n",
    "\n",
    "pl = make_pipeline(\n",
    "    TfidfVectorizer(),\n",
    "    XGBClassifier()\n",
    ")\n",
    "\n",
    "grid = GridSearchCV(pl, param_grid, cv=kf, scoring='roc_auc')\\\n",
    ".fit(x, y)\n",
    "\n",
    "clf = grid.best_estimator_\n",
    "\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7533643892339544, 0.06730802105852025)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This model works well too\n",
    "\n",
    "cv = cross_val_score(clf, x, y, cv=kf, scoring='roc_auc')\n",
    "\n",
    "cv.mean(), cv.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = {}\n",
    "\n",
    "for word, num in clf.named_steps['tfidfvectorizer'].vocabulary_.items():\n",
    "    prob = clf.predict_proba([word])[0][1]\n",
    "    words[word] = prob\n",
    "\n",
    "df_topwords = pd.DataFrame([words]).transpose()\n",
    "df_topwords.columns = ['probability']\n",
    "\n",
    "df_topwords.sort_values('probability', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Default prediction for this model is: 0.014791909605264664\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>appreciate</th>\n",
       "      <td>0.205342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>big</th>\n",
       "      <td>0.103176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>re</th>\n",
       "      <td>0.052137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thought</th>\n",
       "      <td>0.044312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spent</th>\n",
       "      <td>0.033475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>world</th>\n",
       "      <td>0.028655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>having</th>\n",
       "      <td>0.028361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>never</th>\n",
       "      <td>0.025057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>after</th>\n",
       "      <td>0.023248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>listening</th>\n",
       "      <td>0.022401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>0.022328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recently</th>\n",
       "      <td>0.021721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prerequisite</th>\n",
       "      <td>0.020942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>making</th>\n",
       "      <td>0.018648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movies</th>\n",
       "      <td>0.013561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              probability\n",
       "appreciate       0.205342\n",
       "big              0.103176\n",
       "re               0.052137\n",
       "thought          0.044312\n",
       "spent            0.033475\n",
       "world            0.028655\n",
       "having           0.028361\n",
       "never            0.025057\n",
       "after            0.023248\n",
       "listening        0.022401\n",
       "last             0.022328\n",
       "recently         0.021721\n",
       "prerequisite     0.020942\n",
       "making           0.018648\n",
       "movies           0.013561"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mode = mode(df_topwords['probability'])[0][0]\n",
    "\n",
    "print()\n",
    "print('Default prediction for this model is:', df_mode)\n",
    "print()\n",
    "\n",
    "df_topwords[df_topwords.probability != df_mode]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Movies! There it is making an appearance.**\n",
    "\n",
    "# What you don't like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = data['10 things you DON\\'T like'].fillna(' ').astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('tfidfvectorizer', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.10000000000000002, max_features=None,\n",
       "        min_df=3, ngram_range=(1, 1), norm='l2', preprocesso...=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=0, silent=True,\n",
       "       subsample=1))])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'tfidfvectorizer__min_df': [3],#np.arange(1,11,1),\n",
    "    'tfidfvectorizer__max_df': np.arange(.08, .12, .005),\n",
    "    'xgbclassifier__n_estimators': [100],\n",
    "    'xgbclassifier__max_depth': np.arange(2,7,1)\n",
    "}\n",
    "\n",
    "kf = StratifiedKFold(n_splits=3)\n",
    "\n",
    "pl = make_pipeline(\n",
    "    TfidfVectorizer(),\n",
    "    XGBClassifier()\n",
    ")\n",
    "\n",
    "grid = GridSearchCV(pl, param_grid, cv=kf, scoring='roc_auc')\\\n",
    ".fit(x, y)\n",
    "\n",
    "clf = grid.best_estimator_\n",
    "\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7837301587301587, 0.11179491851774788)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This model works works really well but has high variance\n",
    "\n",
    "cv = cross_val_score(clf, x, y, cv=kf, scoring='roc_auc')\n",
    "\n",
    "cv.mean(), cv.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = {}\n",
    "\n",
    "for word, num in clf.named_steps['tfidfvectorizer'].vocabulary_.items():\n",
    "    prob = clf.predict_proba([word])[0][1]\n",
    "    words[word] = prob\n",
    "\n",
    "df_topwords = pd.DataFrame([words]).transpose()\n",
    "df_topwords.columns = ['probability']\n",
    "\n",
    "df_topwords.sort_values('probability', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Default prediction for this model is: 0.008510957472026348\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>late</th>\n",
       "      <td>0.363562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bad</th>\n",
       "      <td>0.181727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>math</th>\n",
       "      <td>0.142716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>when</th>\n",
       "      <td>0.044622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crowds</th>\n",
       "      <td>0.043110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>their</th>\n",
       "      <td>0.033495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>with</th>\n",
       "      <td>0.024671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>running</th>\n",
       "      <td>0.020442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movies</th>\n",
       "      <td>0.013429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food</th>\n",
       "      <td>0.013396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>who</th>\n",
       "      <td>0.012313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>talk</th>\n",
       "      <td>0.011242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>0.010589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hot</th>\n",
       "      <td>0.010370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soda</th>\n",
       "      <td>0.009493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cold</th>\n",
       "      <td>0.009487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drivers</th>\n",
       "      <td>0.009356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spiders</th>\n",
       "      <td>0.009268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>my</th>\n",
       "      <td>0.008429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>traffic</th>\n",
       "      <td>0.007726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>0.006363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>0.005700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>0.005289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>don</th>\n",
       "      <td>0.003590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         probability\n",
       "late        0.363562\n",
       "bad         0.181727\n",
       "math        0.142716\n",
       "when        0.044622\n",
       "crowds      0.043110\n",
       "their       0.033495\n",
       "with        0.024671\n",
       "running     0.020442\n",
       "movies      0.013429\n",
       "food        0.013396\n",
       "who         0.012313\n",
       "talk        0.011242\n",
       "and         0.010589\n",
       "hot         0.010370\n",
       "soda        0.009493\n",
       "cold        0.009487\n",
       "drivers     0.009356\n",
       "spiders     0.009268\n",
       "my          0.008429\n",
       "traffic     0.007726\n",
       "the         0.006363\n",
       "to          0.005700\n",
       "of          0.005289\n",
       "don         0.003590"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mode = mode(df_topwords['probability'])[0][0]\n",
    "\n",
    "print()\n",
    "print('Default prediction for this model is:', df_mode)\n",
    "print()\n",
    "\n",
    "df_topwords[df_topwords.probability != df_mode]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20233338"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Maybe smart people specifically don't like bad movies\n",
    "clf.predict_proba(['bad movies'])[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It also looks like the below-average respondents emphasized more sensory, tangible things they don't like (spiders, hot ____, cold ____. Maybe this is because my \"intelligence\" questions are really measuring openness to experience, which is a measure of idea fluency."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
